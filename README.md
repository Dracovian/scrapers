# Scrapers
This is going to be a repository for random scrapers I've come to develop over the years. These scripts have been published in the intention of data preservation.

## Description
All scrapers in this repository with a brief description

* artic - Grabs art along with metadata from artic.edu 
* calibre-server - Grabs ebooks from a calibre-server
* dafont - Grabs fonts uploaded to dafont.com
* iconmonstr - Grabs icons in all formats from iconmonstr.com
* impawards - Grabs all movie posters from impawards.com
* linfoxdomain - Grabs all flash games from linfoxdomain.com
* memoryoftheworld - Grabs all the books from memoryoftheworld.org
* shzm - Grabs the top 50 songs by city from shazam.com
* thecoverproject - Grabs all the game posters from thecoverproject.net
* theoatmeal - Grabs comics from theoatmeal.com
* wallhaven - Grabs all the images for a given search query from wallhaven.cc
* waset - Grabs papers published to waset.org
* xkcd - Grabs comics posted to xkcd.com


## Others
Scrapers in other repositories

* [acloud-dl by r0oth3x49](https://github.com/r0oth3x49/acloud-dl) - A cross-platform python based utility to download courses from acloud.guru for personal offline use

* [allitebooks-downloader by thomasbrueggemann](https://github.com/thomasbrueggemann/allitebooks-downloader) - üìö Scrapes and downloads all IT eBooks http://allitebooks.com

* [ArchiveBot by ArchiveTeam](https://github.com/ArchiveTeam/ArchiveBot) - ArchiveBot, an IRC bot for archiving websites

* [archivebot-archives by nonPointer](https://github.com/nonPointer/PixivDownloader) - This repository containes a list of files in the ArchiveBot Collection on the Internet Archive and the corresponding codes.

* [archivers by nektro](https://github.com/nektro/archivers) - A collection of scripts to mass download data from various sites

* [ArchiveTools by recrm](https://github.com/recrm/ArchiveTools) - A collection of tools for archiving and analysing the internet

* [Automated-ISO-ripping by pascaldulieu](https://github.com/pascaldulieu/Automated-ISO-ripping) - Short bash script to automatically rip ISOs

* [awesome-dl by Kickball](https://github.com/Kickball/awesome-dl) - This is a list of repositories and libraries that allow for scripted downloading of online content

* [Bios-Archival-Standards by BiosPlus](https://github.com/BiosPlus/Bios-Archival-Standards) - A collection of gists and notes to help me [BiosPlus] standardize my archival efforts accross the board

* [comics-downloader by Girbons](https://github.com/Girbons/comics-downloader) - Command-line tool to download comics and manga in pdf/epub/cbr/cbz from a website

* [Discord-Channel-scraper by simon987](https://github.com/simon987/Discord-Channel-scraper) - Scrapes an arbitrary number of lines from a Discord channel

* [download_scholar_pdfs by bozelosp](https://github.com/bozelosp/download_scholar_pdfs) - Batch .PDF downloading from a list of DOIs and/or titles. PDF files are retrieved/download from libgen scholar archives.

* [DownCloud by seru1us](https://github.com/seru1us/DownCloud) - Download SoundCloud tracks posted on targetted subreddits

* [e621Crawler by fionera](https://github.com/fionera/e621Crawler) - Scrapes images from e621.net (nfsw)

* [flickr-search-scraper by AlexOwen](https://github.com/AlexOwen/flickr-search-scraper) -  Script to capture a JSON file of all search results along with the best version of each image in the search

* [github-scraper](https://github.com/nelsonic/github-scraper) - üï∑Ô∏è üï∏Ô∏è crawl GitHub web pages for insights we can't GET from the API... üí°

* [grab-site by ArchiveTeam](https://github.com/ArchiveTeam/grab-site) - The archivist's web crawler: WARC output, dashboard for all crawls, dynamic ignore patterns

* [lazynlp by chiphuyen](https://github.com/chiphuyen/lazynlp) - Library to scrape and clean web pages to create massive datasets

* [Mega.nz-IDM-downloader by CHEF-KOCH](https://github.com/CHEF-KOCH/Mega.nz-IDM-downloader) - How to download from Mega.nz with IDM - Unlimited

* [Music-Hoarders-Bot by JPBotelho](https://github.com/JPBotelho/Music-Hoarders-Bot) - Discord bot written in python for the music hoarders server

* [PixivDownloader by nonPointer](https://github.com/nonPointer/PixivDownloader) - Simple batch tool to download one's image from Pixiv

* [RedditImageBackup by LameLemon](https://github.com/LameLemon/RedditImageBackup) - Grabs all images, gifs, videos and text posts from Reddit 

* [scihubscraper by mikesuhan](https://github.com/mikesuhan/scihubscraper) - Downloads pdfs of articles from Sci-Hub (sci-hub.tw) based on their DOI

* [scrapereplacementdocs by Itxaka](https://github.com/Itxaka/scrapereplacementdocs) - Scrapy spider to download pdfs from replacementdocs.com

* [wayback-machine-downloader by hartator](https://github.com/hartator/wayback-machine-downloader) - Download an entire website from the Wayback Machine

* [zenpencils-downloader](https://github.com/LameLemon/zenpencils-downloader) - Grabs all comics from zenpencils.com
